\chapter{Conclusion}
Since no data from valid neural scans researching the same or a similar topic was provided, the project is heavily theory based (in comparison to~\cite{StBoGe17HPM}), which makes the interpretation of the results a priori not easy because a quantitative and qualitative frame of reference is missing. There were sharp results produced in \secreff{sec: first model and architecture MR}, but they are too artificial to draw relevant conclusions regarding the objective and neuroscientist won't collect data as clear.

While trying to reproduce them \ie getting as close as possible, many architectures were unsuccessfully tested and evaluated as mentioned in \appref{ch: additional configurations}. Therefore, the process of finding a proper one consumed many weeks with discussions between my advisor and me. Maybe, the goals were slightly too ambitious. Additionally, they more or less led to the same results covered in this thesis, especially in \secreff{sec: text based models and architecture}. Although, the values calculated in \tabref{\ref{tab: text model versions and metrics}} are relatively low and close to $ 0 $, which means a perfect fit according to \secreff{sec: metric}, the metric $ d_A $ itself isn't justified for more than internal comparisons of the configurations. It was developed to have a sensible measure on the results because plots of high dimensional sparse matrices, which are just monochromatic squares, aren't convincing. From the figures in \tabref{\ref{tab: text model versions and metrics}} \& \tabref{\ref{tab: avg model versions and metrics}} can be deduced that models training with word vectors have an unsatisfactory performance in comparison to their equivalents working with \onehot{s}. This is unsatisfying for two reasons: Firstly, getting the approach working costed much time because the implementation of the mechanics \spacy{} offers and integrating them into the concept of the \cognitiveroom{} were the most elaborate part in the process of building the framework and secondly, because the input received by the hippocampus is probably closer to a word vector than to a \onehot{}. Translating it into a neuroscience behavior, it can be compared with receiving plenty of signals as input against processing one (strong) activation from another cell.

By presenting the topic in front of my colloquium, further approaches were gathered. One of them, the idea of averaging the predictions of one word class and analyzing the outcome, paid off (s. \secreff{subsubsec: average approach} \& \secreff{sec: average approach}). The results found there can function as addition to the plain word models because they prove that these models can grasp the grammatical structure. Therefore, they can provide visual feedback even in large dimensional contexts and by calculating the ground truth distribution there is a useful reference.

But nevertheless, the \onehot{} variant can serve as foundation for further (minor) research, for instance developing a better metric to have a mathematical notion of encoding a good and objective value or tweaking the learning with word vectors due to the better compatibility with hippocampal functions. Of great value would be collected data from an analogue survey conducted by neuroscientist \ie analyzing the activity of the hippocampus, the place and grid cells while participants process new pieces of language. Then is a viable environment, as in~\cite{StBoGe17HPM}, given and the theory may be expanded to language related topics as it is to spatial navigation.
