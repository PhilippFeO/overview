\section{Average approach} \label{subsubsec: average approach}
Because the models become enormous and  especially thus the evaluation difficult, this configuration aims to analyze the results on a rougher scale by taking averages of the predictions. While collecting the training data, the \postag{} of each one is saved and after training the cumulative outputs of a word class prediction are taken \ie all \onehot{s} of a \texttt{VERB} are mapped by the Neural Network, averaged into one vector and then checked for the most probable \postag{s} (\secreff{sec: average approach}).

\postag{s} were mentioned before in \secreff{sec: data preparation} and are just another term for word classes. In detail, a subset of the UniversalDependencies \postag{s}~\cite{udpostags} are used (\tabref{\ref{tab: ud pos tags}}) because this project provides a rich dataset, good documentation and its guidelines are implemented by \spacy{}.
\begin{table}
	\centering
	\caption[Listing of \postag{s}.]{List of relevant \postag{s} including examples and short definition.}
	\begin{tabular}{cl|cl}
		\toprule
		\postag{} 	  & Definition \& Example 		& \postag{} 		& Definition \& Example \\
		\midrule
		\texttt{ADJ}  & Adjective: educated, hot 	& \texttt{VERB} 	& Verb: to run, to drink \\
		\texttt{ADV}  & Adverb: easily, everywhere	& \texttt{DET} 		& Determiner: this, a, no \\
		\texttt{NOUN} & Noun: car, bottle 			& \texttt{PART}		& Particle: 's, not \\
		\texttt{AUX}  & Auxiliary: to have, should 	& \texttt{ADP}		& Adposition (Pre- \& Postpositions): in, on \\
		\texttt{PRON} & Pronoun: she, ours 			& \texttt{REST}		& \parbox{7cm}{Rest (Container for Conjunctions and additional residuals): and, if}\\
		\bottomrule
	\end{tabular}
	\label{tab: ud pos tags}
\end{table}
%In the next step the $ n $ indices with the highest values are checked for their word class, so if index $ i $ is one of the $ n $ highest and encodes the word \texttt{fish}, its word class \texttt{Noun} is counted. Finally, one has constructed a vector for each word class where each component resembles the probabilities after dividing by $ n $ for the following word class. An estimation of the \gls{sr} could look like the matrix in \eqref{eq: example average sr matrix} for the three word classes \texttt{Verb}, \texttt{Adjective} and \texttt{Noun} \ie the predicted transition probability for \texttt{Verb â†’ Noun} is equal to $ 0.8 $, etc.
%\begin{equation} \label{eq: example average sr matrix}
%	\begin{pmatrix}
%		0 & 0.2 & 0.8 \\
%		0.1 & 0.3 & 0.6 \\
%		0.7 & 0.2 & 0.1
%	\end{pmatrix}
%\end{equation}
